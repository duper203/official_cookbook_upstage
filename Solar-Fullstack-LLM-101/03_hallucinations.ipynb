{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFAyDWd_So7F"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/03_hallucinations.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR6QI343So7G"
      },
      "source": [
        "# 03. Hallucinations\n",
        "## Overview  \n",
        "In this exercise, we will explore the concept of hallucinations in large language models using the Solar framework. Hallucinations refer to instances where the model generates information that is not based on the input data or is factually incorrect. This notebook will help you understand why hallucinations occur and how to mitigate them to ensure the reliability and accuracy of the model's outputs.\n",
        "\n",
        "## Purpose of the Exercise\n",
        "The purpose of this exercise is to identify and address the issue of hallucinations in language models. By the end of this tutorial, users will be able to recognize hallucinations, understand their causes, and apply strategies to minimize their occurrence, thereby improving the trustworthiness and usability of the Solar LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "82Q8QyidSo7H",
        "outputId": "8a628853-f811-4471-b0c1-fc2f4e7dca65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.5/383.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip3 install -qU langchain-upstage python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BVVji6UCSo7H"
      },
      "outputs": [],
      "source": [
        "# @title set API key\n",
        "from pprint import pprint\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from IPython import get_ipython\n",
        "\n",
        "upstage_api_key_env_name = \"UPSTAGE_API_KEY\"\n",
        "\n",
        "\n",
        "def load_env():\n",
        "    if \"google.colab\" in str(get_ipython()):\n",
        "        # Running in Google Colab\n",
        "        from google.colab import userdata\n",
        "\n",
        "        upstage_api_key = userdata.get(upstage_api_key_env_name)\n",
        "        return os.environ.setdefault(\"UPSTAGE_API_KEY\", upstage_api_key)\n",
        "    else:\n",
        "        # Running in local Jupyter Notebook\n",
        "        from dotenv import load_dotenv\n",
        "\n",
        "        load_dotenv()\n",
        "        return os.environ.get(upstage_api_key_env_name)\n",
        "\n",
        "\n",
        "UPSTAGE_API_KEY = load_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z7vXj-gwSo7H",
        "outputId": "b56144e8-00db-4edc-9271-e76fb86931a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"DUS, or Document Understanding Service, is an AI solution developed by Upstage that specializes in processing, analyzing, and extracting information from various types of documents. It's designed to help businesses automate and streamline their document-driven workflows.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_upstage import ChatUpstage\n",
        "\n",
        "llm = ChatUpstage(model=\"solar-pro\")\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Q: What is DUS developed from Upstage?\n",
        "\n",
        "A:\n",
        "\"\"\"\n",
        ")\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "chain.invoke({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nh8EkSEySo7I",
        "outputId": "ff336620-b3c3-4af0-d390-d4fd09a4d038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"DUS stands for Duplex Unified Server. It's a software product developed by Google to enable their AI assistant, Google Duplex, to make phone calls on behalf of users. This can be useful for tasks like scheduling appointments or making reservations.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_upstage import ChatUpstage\n",
        "\n",
        "llm = ChatUpstage(model=\"solar-pro\")\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Q: What is DUS developed from Google?\n",
        "\n",
        "A:\n",
        "\"\"\"\n",
        ")\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "chain.invoke({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk7ncsGUSo7I"
      },
      "source": [
        "![hallucination](https://github.com/UpstageAI/cookbook/blob/main/Solar-Fullstack-LLM-101/figures/hallucination.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy0tBDUQSo7I"
      },
      "source": [
        "## Next Token Prediction\n",
        "They are designed to generate the next words. It's also very difficult to know what we don't know.\n",
        "\n",
        "![](https://jalammar.github.io/images/xlnet/gpt-2-autoregression-2.gif)\n",
        "\n",
        "Image from https://jalammar.github.io/illustrated-gpt2/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXAqMmrTSo7I"
      },
      "source": [
        "# Excercise\n",
        "\n",
        "Think of ways to prevent Large Language Models (LLMs) from generating incorrect information."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}